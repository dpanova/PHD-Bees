from BeeLitReview import BeeLitReview
review = BeeLitReview()
# review.researchgate_scraper()
review.scraped_data_enhancement()
review.encode_with_transformers()
review.calculate_similarity()
review.calculate_TSP()
#TODO


#%%
#review.most_similar.iloc[0]

review.clustering_evaluation( cosine_threshold = 0.5
                        ,year=2023
                        ,type = ['Article', 'Conference Paper','Preprint','Patent','Thesis']
                        ,read = 10
                        ,citation = 1)

#%%
review.pdf_report_generate()


#%%
import numpy as np
import pandas as pd

review.clustering_indices
clustered_df = review.df[review.df['index'].isin(review.clustering_indices)]
clustered_df['HDBSCAN Labels'] = review.ce_hdbscan_results['labx']
clustered_df['AGG Labels'] = review.ce_agg_results['labx']




#%%
#define a function for the table format table creation
#TODO an issue here with the pd_to_tuple

#%%


#%%

# Generate the PDF report and save it
pdf = FPDF('P', 'mm', 'A4')

# PAGE 1
"""
Here we have:
- INTRO: Report title, author, data of the report and disclaimer and dependant variable distribution
- DATA OVERVIEW - Time distribution, word distribution, result type, language 
"""

# INTRO
start_page(pdf)

h0('Literature Review Automated Report',pdf)

normal_text('Author: Denitsa Panova',pdf, x=3,  italics=True)
normal_text('Date: '+datetime.today().strftime('%Y-%m-%d'), pdf, italics=True)

text = ('Disclaimer: The objective of this report is to present the outcomes generated by automated literature research. '
        'A specialized interpretation is essential to derive accurate conclusions regarding correct articles to '
        'be reviewed.')

normal_text(text,pdf,italics=True, x = 10)


h1('Data Overview',pdf)

text = ('Query "%s" has been executed in researchgate.com and all available results are scraped - in total %s. '
        'Note, that in the context of this report, a result is a search result, it can be an article, '
        'presentation, etc.') %(review.query,str(len(review.df)))
normal_text(text,pdf)

h2('Time Distribution',pdf)
normal_text("Firstly, we will investigate how the results's distribution over the years.", pdf)

#Table for the time distribution over years
year_data = pd_to_tuple(review.df,'Year')

pdf_table(year_data,pdf,width=40,cols=(20,20))

h2('Word Distribution', pdf)

text = ("Then, we will investigate what is the average count of words per abstract. Here the goal is to see if the "
        "default transformer model is still an adequate solution.The default model is all-mpnet-base-v2 and if the "
        "word count is above 384, it truncates the text and we wouldn't have full results in the encoding stage. "
        "We have %s of the results consenting the criteria."
        %str(round(sum(review.df['Abstract Count Words'] <= 384.0) / len(review.df),2)))

normal_text(text,pdf)

plot_code = "review.df['Abstract Count Words'].hist()"
pdf_graph(pdf,plot_code = plot_code, x = 50, y = 206, w = 110, h = 0)

#NEW PAGE
start_page(pdf)
h2('Result type',pdf)
text = ("Investigate what type of results are extracted. This will help in the correct choice for clustering the results. "
        "The default types for clustering are: Article and Conference Paper.")
normal_text(text, pdf)
type_data = pd_to_tuple(review.df,'Text Type')
pdf_table(type_data,pdf,width=60,cols=(40,20))

h2('Language',pdf)
text = ("Investigate what languages the results are in. We are considering only English languages for the purposes of "
        "this research After removing non-English results, we lose %s of the data."
        %str(round(len(review.df_raw[review.df_raw['Language']!='en'])/len(review.df_raw),2)))

normal_text(text, pdf)

language_data = pd_to_tuple(review.df_raw,'Language')
pdf_table(language_data,pdf,width=40,cols=(40,20))

h1('Optimal ML Path',pdf)
h2('Traveling Salesmen Problem (TSP)',pdf)

initial_point = str(review.most_similar.iloc[0])
text = ("Each abstract is turned into an embedding, using the HuggingFace Transformer. The default one is "
        "all-mpnet-base-v2.After we calculate similarity between each scraped result with each another one, we apply TSP "
        "for finding the shortest path. The time for calculating it is %s ms. Additionally, to optimize the performance "
        "of the algorithm by creating an artificial connection in the graph between the query %s and the most similar "
        "result in terms of cosine similarity between embeddings. Then we artificially assigned similarity 0 to "
        "impose the algorithm to start from there. The result index is %s"
        %(str((review.graph_end - review.graph_start) * 10 ** 3),review.query,initial_point))

normal_text(text,pdf)

h2('Similarity Difference',pdf)

#TODO change with the self path
# path = pd.read_csv('path.csv')
#select only the inspected articles
path = pd.DataFrame(review.path[:50])
#create tuples based on the path pairs
path_similarity = pd.DataFrame()
path_similarity['pair0'] = list(path.iloc[:-1,0])
path_similarity['pair1'] = list(path.iloc[1:,0])
path_similarity = path_similarity.merge(review.similarity_df, how='inner', on = ['pair0','pair1'])


#let us do the same for the original research order
original_similarity = pd.DataFrame()
original_similarity['pair0'] = list(range(0,49))
original_similarity['pair1'] = list(range(1,50))
original_similarity = original_similarity.merge(review.similarity_df, how='inner', on = ['pair0','pair1'])


text = ("In order to investigate what is the added value of TSP, we check what is the average similarity measure"
        "in the first 50 TSP-suggested articles and the first 50 ResearchGate articles. TSP is %s and ResearchGate is %s."
        %(str(round(path_similarity['cos'].mean(),2)),str(round(original_similarity['cos'].mean() ,2))))

normal_text(text,pdf)

h2('Time Saved', pdf)

all_not_read_indix = list(set(list(review.df['index'])).difference(set(list(path.loc[:, 0]))))
all_not_read_indix_max = [x for x in all_not_read_indix if x < max(list(list(path.loc[:, 0])))]
# the cost in terms of time
cost_time = str(round(review.df.loc[all_not_read_indix_max, 'Abstract Count Words'].sum() / 150 / 60,2))  # 12 hours
text = ("Now we will calculate how much time it is saved by following the 50 articles suggested by TSP. The goal is to "
        "understand how much time is saved and at the same time wider knowledge on the topic is acquired. The metric "
        "encompasses the number of abstracts one should go over to read the same TSP-suggested results. According "
        "to a research, one can read around 150 words per minute. Therefore, the saved time by going with the TSP "
        "suggestion is %s hours." %cost_time)

normal_text(text,pdf)

h2('TSP Results of Interest',pdf)
normal_text('Let us look into the wordcloud of the TSP-results abstracts to see what those are in one look.', pdf,x = 0)

#TODO change to self
# to_review_df = pd.read_excel('to_review.xlsx')

words = nltk.word_tokenize(' . '.join(list(review.to_review_df['Title'])))

stop_words = set(stopwords.words('english'))

stemmer = SnowballStemmer("english")
words = [stemmer.stem(word.lower())
         for word in words
         if word.isalnum() and word.lower() not in stop_words]
word_freq = {}
for word in words:
    if word in word_freq:
        word_freq[word] += 1
    else:
        word_freq[word] = 1
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)

plot_code = ("plt.imshow(wordcloud, interpolation='bilinear') \n"
             "plt.axis('off')")
pdf_graph(pdf,plot_code=plot_code, x = 0, y = 100, w = 200, h = 0)
pdf.ln(115)
normal_text('The next step is to look into the TSP results and identify those which are of interest for the research.'
            'We have identified those:',pdf)

#TODO in the reading part of the excel in the ufnction
review.to_review_df['Choose'] = review.to_review_df['Choose'].astype('bool')
for idx,row in review.to_review_df[review.to_review_df['Choose']].iterrows():
    normal_text('Original Index: ' + str(row['index']), pdf)
    normal_text('Title: ' + row['Title'],pdf)


h2('Clustering Results',pdf)
normal_text("Let us see the distribution of the HDBSCAN clusters.", pdf)

hdbscan_data = pd_to_tuple(pd.DataFrame(review.ce_hdbscan_results['labx'], columns=['Label']),'Label')
hdbscan_table = pdf_table(hdbscan_data,pdf,width=40,cols=(20,20))

normal_text("Note: -1 label is for the outliers", pdf, italics=True)

normal_text('Let us see the dendogram of the HDBSCAN clusters.', pdf)
start_page(pdf)
pdf_graph(pdf,with_code=False, filename="dendogram_hdbscan.png", x = 0, y = 10, w = 200, h = 0)


pdf.ln(130)
normal_text("Let us see the distribution of the Agglomeration clusters.", pdf)

pdf.ln(10)
agg_data = pd_to_tuple(pd.DataFrame(review.ce_agg_results['labx'], columns=['Label']),'Label')
agg_table = pdf_table(agg_data,pdf,width=40,cols=(20,20))

normal_text('Let us see the dendogram of the Agglomeration clusters.', pdf)
start_page(pdf)
pdf_graph(pdf,with_code=False, filename="dendogram_agg.png", x = 0, y = 10, w = 200, h = 0)


pdf.ln(140)
h1('Suggested Reads',pdf)

text = ("We will remove the outlier results (those which are classified from HDBSCAN) and show the rest as per the "
        "Agglomeration clustering technique.")
normal_text(text, pdf)

import numpy as np
import pandas as pd

clustered_df = review.df[review.df['index'].isin(review.clustering_indices)]
clustered_df['HDBSCAN Labels'] = review.ce_hdbscan_results['labx']
clustered_df['AGG Labels'] = review.ce_agg_results['labx']
clustered_df = clustered_df[clustered_df['HDBSCAN Labels']!=-1]
# clustered_df.sort_values(by=['AGG Labels'],inplace=True)
clusters = clustered_df['AGG Labels'].unique()
# clustered_df['Title'].replace('[\W_]+','')
for cluster in clusters:
    h2('Cluster ' + str(cluster),pdf)
    for idx,row in clustered_df[clustered_df['AGG Labels']==cluster].iterrows():
        try:
            normal_text('Original Index: ' + str(row['index']), pdf)
            normal_text('Title: ' + row['Title'],pdf)
            normal_text(row['URL'], pdf)
        except:
            print(row['index'])
            normal_text('Original Index: ' + str(row['index']), pdf)
            normal_text('No Title: ', pdf)
            normal_text(row['URL'], pdf)


#%%

pdf.output('lit_report.pdf', 'F')



